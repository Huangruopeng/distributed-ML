# Intro to Distributed Machine Learning

# Content

<!-- [1.Definition](#1.definition )
- [2.Origin](#2.origin)
- [3.Solve what problems?](#(3.)solve-what-problems?)
  - [3.1.How to use statistics and optimization theory and algorithms?](#3.1.how-to-use-statistics-and-optimization-theory-and-algorithms?)
  - [3.2.How to develop ML models or training algorithms that are more suitable for distributed settings？](#3.2.how-to-develop-ML-models-or-training-algorithms-that-are-more-suitable-for-distributed-settings？)-->
  
<a href="#head1">1.Definition</a><br/>
<a href="#head2">2.Origin</a><br/>
<a href="#head3">3.Solve what problems?</a><br/>
&emsp;<a href="#head3.1">3.1.How to use statistics and optimization theory and algorithms?</a><br/>
&emsp;<a href="#head3.2">3.2.How to develop ML models or training algorithms that are more suitable for distributed settings？</a><br/>
&emsp;<a href="#head3.3">3.3.How to build large-scale DML applications？</a><br/>
&emsp;<a href="#head3.4">3.4.How to develop parallel or distributed computer systems to scale up ML？</a><br/>
<a href="#head4">4.Understanding Distributed Deep Learning</a><br/>
&emsp;<a href="#head4.1">4.1.Terminology</a><br/>
&emsp;&emsp;<a href="#head4.1.1">4.1.1.Data Parallelism</a><br/>
&emsp;&emsp;<a href="#head4.1.2">4.1.2.Model Parallelism</a><br/>
&emsp;<a href="#head4.2">4.2.Problems in distributed machine learning</a><br/>



<a id="head1"/>
  
## 1.Definition
一般而言, **分布式机器学习 (DML)** 是一个跨学科领域, 涉及计算机科学的几乎每一个角落-理论领域 (如统计学,学习理论,和优化), 算法,核心机器学习(深度学习,图形模型,内核方法等), 甚至分布式和存储系统。在这些子域中, 有无数的问题需要探索和研究。另一方面, DML 也是工业生产中最广泛采用和部署的 ML 技术, 因为它拥有大量的数据。
![DML](https://raw.githubusercontent.com/Huangruopeng/distributed-ML/master/pictures/distributed%20learning.PNG)


<a id="head2"/>

## 2.Origin
分布式机器学习是随着“大数据”概念兴起的。在有大数据之前，有很多研究工作为了让机器学习算法更快，而利用多个处理器。这类工作通常称为“**并行计算**”或者“并行机器学习”，其核心目标是把计算任务拆解成多个小的任务，分配到多个处理器上做计算。分布式计算或者分布式机器学习除了要把计算任务分布到多个处理器上，更重要的是把计算数据（包括训练数据以及中间结果）分布开来。因为在大数据时代，一台机器的硬盘往往装不下全部数据，或者即使装下了，也会受限于机器的I/O通道的带宽，以至于访问速度很慢。为了更大的存储容量、吞吐量以及容错能力，我们都希望把数据分布在多台计算机上。
![AI](https://raw.githubusercontent.com/Huangruopeng/distributed-ML/master/pictures/AI%20history.PNG)<font color=gray size=3>*人工智能发展历史*</font>


<a id="head3"/>

## 3.Solve what problems?
如果你把它分成四类研究问题, 那么最容易理解 DML。但是, 请注意, 这些类绝对不是互斥的。

<a id="head3.1"/>

### 3.1.How to use statistics and optimization theory and algorithms?
我们倾向于关注以下问题:


* 优化过程需要多长时间才能达到收敛性？
* 融合解决方案有多好？
* 需要多少训练数据才能保证一个好的解决方案？
  
  

为了研究这些问题, 研究人员求助于理论分析工具, 如优化理论或统计学习理论。然而, 在大规模的 ML 环境下, 我们得到了更多的计算资源, 我们的目标是通过并行或分布式计算技术利用额外资源来加速 (即减少模型的训练/测试时间), 我们真的想找出另一套类似的, 但不同的问题:

* 通过分布式或并行训练, 我们的模型和参数是否保证在同一个状态下收敛而不加速？
* 如果它们不收敛于相同的状态, 那么我们从原来的解决方案中得到了多远, 我们从真正的最佳解决方案中得到了多远？
* 还需要哪些其他假设/条件才能达到 "良好" 的收敛性？
* 如果将分布式培训与非分布式培训进行比较, 我们能获得多快 (即可伸缩性)？我们如何评估这一点？
* 我们如何设计培训过程 (例如数据取样、参数更新) 以确保良好的可伸缩性和良好的收敛性？

<a id="head3.2"/>

### 3.2.How to develop ML models or training algorithms that are more suitable for distributed settings？
这条研究的重点是开发新的 ML 模型或调整 (放大) 现有的模型, 以处理更大的规模数据。

<a id="head3.3"/>

### 3.3.How to build large-scale DML applications？
还有一些具体的应用问题, 如大规模的图像分类, 需要研究, 以扩大非常具体的模型/算法。这些解决方案中的大多数可以直接部署到生产线中。

<a id="head3.4"/>

### 3.4.How to develop parallel or distributed computer systems to scale up ML？
这条线的研究是相当直观的-如果我们的模型或算法不能完成一个节点上的计算工作流, 我们可以尝试开发分布式系统使用更多的节点 (因此, 更多的计算资源)。但是, 要做到这一点, 我们需要面对很多系统问题:
* 一致性: 如果它们同时朝着一个目标努力, 我们如何确保多个节点的协商一致？例如, 如果它们一起解决了一个优化问题, 但数据集的不同分区怎么办？
* 容错能力: 如果我们将工作负载分配到1000年计算节点的集群中, 那么如果1000个节点中的一个崩溃了怎么办？除了从一开始就重新启动工作之外, 还有什么方法可以修复它吗？
* 通信: ML 涉及很多 i/o ( 如磁盘读写) 和数据处理程序, 我们可以设计存储系统, 以便为不同类型的环境实现更快的 i/o 和非阻塞数据处理过程 (例如, 单节点本地磁盘、分布式文件系统、 CPU i/o、 GPU i/o 等)？
* 资源管理: 构建计算机群集成本高昂, 因此集群通常由许多用户共享。我们应如何管理群集, 并适当地分配资源以满足每个人的请求, 同时最大限度地使用？
* 编程模型: 我们是否应该以与非分布式系统相同的方式规划分布式 ML 模型/算法？我们可以设计一个新的编程模型, 需要更少的编码和提高效率吗？我们可以在单节点的方式下编程, 同时用分布式计算技术自动放大程序吗？

<a id="head4"/>

# 4.Understanding Distributed Deep Learning
分布式深度学习是一般分布式机器学习的一个子领域, 由于其在各种应用中的有效性, 最近变得非常突出。

<a id="head4.1"/>

## 4.1.Terminology
在深入研究分布式深度学习的本质和它所处理的问题之前, 我们应该定义一些重要的术语: **数据并行性(Data Parallelism)和模型并行性(Model Parallelism).**

<a id="head4.1.1"/>

### 4.1.1.Data Parallelism
数据并行化是通过对数据进行分区来启用的并行化技术。在数据并行分布式计算中, 我们首先将数据划分为几个分区, 分区数等于工作机 (即计算节点) 的数目。然后, 我们让每个工人拥有一个独立的分区, 让他们对这些数据执行计算。由于我们有多个节点并行地扫描数据, 所以我们应该能够比使用单个节点时扫描更多的数据-我们通过分布式并行计算提高吞吐量。</br>
</br>
在分布式机器学习中, 我们的目标是通过多个节点加速模型训练的收敛性, 应用数据并行度相当直观: 我们让每个机器自己进行训练 (即随机梯度下降)。数据分区, 并生成一组参数更新 (即渐变)。然后, 我们让所有节点通过网络通信同步其参数状态, 直到它们达成共识为止。只要同步不花费太多的时间, 我们看到改善单节点的结果, 我们已经达到了我们的目标!基本上, 这是谷歌的深层学习系统DistBelief工作的方式。

<a id="head4.1.2"/>

### 4.1.2.Model Parallelism
与数据并行度相比, 模型并行度是一个较为复杂和模糊的概念。一般而言, 在模型并行度中, 我们试图将机器学习模型本身划分为多个计算工作者, 而不是划分数据。例如, 假设我们正在解决一个矩阵分解问题, 矩阵是超级大的, 我们要学习这个巨大矩阵的每个参数。为了应用模型并行性, 我们必须将矩阵划分为许多小块 (子矩阵), 然后让每个工作者来处理一些。这样, 如果一个节点上的 RAM 不足以存储矩阵中的所有参数, 我们就能够利用多个节点的额外RAM 。由于不同的节点有不同的工作负载映射到不同的矩阵块, 当他们并行计算时，速度会有所提升。</br>
</br>
问题是, 我们应该如何划分模型？由于我们有这么多的机器学习模型, 每个模型都有自己的特点和表示, 所以没有实现模型并行性的原则方法。

<a id="head4.2"/>

## 4.2.Problems in distributed machine learning
当训练数据的大小更大时, 数据并行性非常有效, 因为我们可以用其他节点更快地扫描数据。模型并行性更适用于模型大小对于一个节点来说太大的情况, 因为它允许我们对模型进行分区, 并在多个节点上利用额外的内存。</br></br>
理想情况下, 在分布式计算中, 我们希望得到与分配的机器数量一样多的 speedups (我们通常称之为 "可伸缩性")。详细地来说, 如果我们分配K机器, 并且我们的系统可以扫描数据K倍速度比在一个单一的节点在单位时间, 那么我们的系统具有可伸缩性K, 或线性可伸缩性。线性可伸缩性是这些系统的理想选择。
<br/><br/>
由于同步任务造成的开销, 在分布式计算机群集上完成一次培训的迭代通常要比在单个节点上花费更长的时间。在计算结束时, 我们必须花费额外的时间在多个节点之间同步 (网络通信), 以确保 ML 训练任务的收敛性。在实际操作中, 同步可以花费的时间只要计算, 甚至更长。
<br/><br/>
为什么？一个主要原因是群集中的某些工作节点运行速度比其他节点慢 (因为硬件更便宜或更旧), 为了与它们同步, 更快的员工必须等到他们的计算作业完成-系统性能总是由较慢的工人界。在这些情况下, 将K机组合在一起可能会导致负的可伸缩性, 这是浪费时间和金钱的巨大原因。

<a id="head5"/>

# 5.Distributed machine learning computing framework：MPI
Message Passing interface(MPI)是1994年5月发布的一种消息传播接口，它实际上是一个消息传播函数库的标准说明，吸收了众多消息传递系统的优点，是目前国际上最流行的并行编程环境之一。
![MPI](https://raw.githubusercontent.com/Huangruopeng/distributed-ML/master/pictures/MPI.PNG)
MPI具有许多的优点
* 具有可移植性和易用性
* 有完备的异步通信的功能
* 有正式和详细的精确定义

在基于MPI编程模型中，计算是由一个或多个彼此通过调用库函数进行消息收发，通信的进程所组成在绝大部分MPI实现中，一组固定的进程。在程序初始化的时候产生。一般情况下，一个处理器只生成一个进程，这些进程可以执行相同或不同的程序进程间的通信，可以是点到点也可以是集合的。MPI提供了一个并行环境库，通过调用MPI的库函数来达到并行的目的。目前流行的实现包括MPICH和OpenMPI。








