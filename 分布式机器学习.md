#Intro to Distributed Machine Learning
##1.Definition
一般而言, **分布式机器学习 (DML)** 是一个跨学科领域, 涉及计算机科学的几乎每一个角落-理论领域 (如统计学,学习理论,和优化), 算法,核心机器学习(深度学习,图形模型,内核方法等), 甚至分布式和存储系统。在这些子域中, 有无数的问题需要探索和研究。另一方面, DML 也是工业生产中最广泛采用和部署的 ML 技术, 因为它拥有大量的数据。

##2.Origin
分布式机器学习是随着“大数据”概念兴起的。在有大数据之前，有很多研究工作为了让机器学习算法更快，而利用多个处理器。这类工作通常称为“**并行计算**”或者“并行机器学习”，其核心目标是把计算任务拆解成多个小的任务，分配到多个处理器上做计算。分布式计算或者分布式机器学习除了要把计算任务分布到多个处理器上，更重要的是把计算数据（包括训练数据以及中间结果）分布开来。因为在大数据时代，一台机器的硬盘往往装不下全部数据，或者即使装下了，也会受限于机器的I/O通道的带宽，以至于访问速度很慢。为了更大的存储容量、吞吐量以及容错能力，我们都希望把数据分布在多台计算机上。

##3.Solve what problems？
如果你把它分成四类研究问题, 那么最容易理解 DML。但是, 请注意, 这些类绝对不是互斥的。
###3.1.How to use statistics and optimization theory and algorithms?
我们倾向于关注以下问题:

* 优化过程需要多长时间才能达到收敛性？
* 融合解决方案有多好？
* 需要多少训练数据才能保证一个好的解决方案？
  
为了研究这些问题, 研究人员求助于理论分析工具, 如优化理论或统计学习理论。然而, 在大规模的 ML 环境下, 我们得到了更多的计算资源, 我们的目标是通过并行或分布式计算技术利用额外资源来加速 (即减少模型的训练/测试时间), 我们真的想找出另一套类似的, 但不同的问题:

* 通过分布式或并行训练, 我们的模型和参数是否保证在同一个状态下收敛而不加速？
* 如果它们不收敛于相同的状态, 那么我们从原来的解决方案中得到了多远, 我们从真正的最佳解决方案中得到了多远？
* 还需要哪些其他假设/条件才能达到 "良好" 的收敛性？
* 如果将分布式培训与非分布式培训进行比较, 我们能获得多快 (即可伸缩性)？我们如何评估这一点？
* 我们如何设计培训过程 (例如数据取样、参数更新) 以确保良好的可伸缩性和良好的收敛性？

###3.2.How to develop ML models or training algorithms that are more suitable for distributed settings？
这条研究的重点是开发新的 ML 模型或调整 (放大) 现有的模型, 以处理更大的规模数据。

###3.3.How to build large-scale DML applications？
还有一些具体的应用问题, 如大规模的图像分类, 需要研究, 以扩大非常具体的模型/算法。这些解决方案中的大多数可以直接部署到生产线中。

###3.4.How to develop parallel or distributed computer systems to scale up ML？
这条线的研究是相当直观的-如果我们的模型或算法不能完成一个节点上的计算工作流, 我们可以尝试开发分布式系统使用更多的节点 (因此, 更多的计算资源)。但是, 要做到这一点, 我们需要面对很多系统问题:
* 一致性: 如果它们同时朝着一个目标努力, 我们如何确保多个节点的协商一致？例如, 如果它们一起解决了一个优化问题, 但数据集的不同分区怎么办？
* 容错能力: 如果我们将工作负载分配到1000年计算节点的集群中, 那么如果1000个节点中的一个崩溃了怎么办？除了从一开始就重新启动工作之外, 还有什么方法可以修复它吗？
* 通信: ML 涉及很多 i/o ( 如磁盘读写) 和数据处理程序, 我们可以设计存储系统, 以便为不同类型的环境实现更快的 i/o 和非阻塞数据处理过程 (例如, 单节点本地磁盘、分布式文件系统、 CPU i/o、 GPU i/o 等)？
* 资源管理: 构建计算机群集成本高昂, 因此集群通常由许多用户共享。我们应如何管理群集, 并适当地分配资源以满足每个人的请求, 同时最大限度地使用？
* 编程模型: 我们是否应该以与非分布式系统相同的方式规划分布式 ML 模型/算法？我们可以设计一个新的编程模型, 需要更少的编码和提高效率吗？我们可以在单节点的方式下编程, 同时用分布式计算技术自动放大程序吗？


